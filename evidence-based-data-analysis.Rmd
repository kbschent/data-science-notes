---
title: "Evidence-Based Data Analysis"
output: html_document
---

### Replication and Reproducibility
- Replication  
    - Focuses on the validity of the scientific claim  
    - "Is this claim true"  
    - The ultimate standard for strengthening scientific evidence  
    - New investigators, data, analytical methods, laboratories, instruments, etc.  
    - Particularly important in studies that can impact broad policy or regulatory decisions  
- Reproducibility  
    - Focuses on the validity of the data analysis  
    - "Can we trust this analysis"  
    - Arguably a minimum standard for any scientific study  
    - New investigators, same data, same methods  
    - Important when replication is impossible 

### Background and Underlying Trends  
- Some studies cannot be replicated: No time, no money, unique/opportunistic  
- Technology is increasing data collection throughput, data are more complex and high-dimensional  
- Existing databases can be merged to become bigger databases (but data are used off-label)  
- Computing power allows more sophisticated analyses, even on "small" data  
- For every field "X" there is a "Computational X"  

### The Result?  
- Even basic analyses are difficult to describe  
- Heavy computational requirements are thrust upon people without adequate training in statistics and computing  
- Errors are more easily introduced into long analysis pipelines  
- Knowledge of transfer is inhibited  
- Results are difficult to replicate or reproduce  
- Complicated analyses cannot be trusted  

### What Problem Does Reproducibility Solve?  
What we get  
- Transparency  
- Data Availability  
- Software/Methods Availability  
- Improved Transfer of Knowledge  

What we do NOT get  
- Validity/Correctness of the analysis  

An analysis can be reproducible and still be wrong  
  
We want to know "can we trust this analysis?"  
  
Does requiring reproducibility deter bad analysis?

### Problems with Reproducibility  
The premise of reproducible research is that with data/code available, people can check each other and the whole system is self-correcting  
- Addresses the most "downstream" aspect of the research process - post-publication  
- Assumes everyone plays by the same rules and wants to achieve the same goals (i.e., scientific discovery)

### Scientific Dissemination Process
TODO: Add description/summary

### Who Reproduces Research?  
- For reproducibility to be effective as a means to check validity, someone needs to do something  
    - Re-run the analysis; check results match  
    - Check the code for bugs/errors  
    - Try alternate approaches; check sensitivity  
- The need for someone to do something is inherited from traditional notion of replication  
- Who is "someone" and what are their goals?  

### The Story So Far  
- Reproducibility brings transparency (wrt code + data) and increased transfer of knowledge  
- A lot of discussion about how to get people to share data  
- Key question of "can we trust this analysis?" is not addressed by reproducibility  
- Reproducibility addresses potential problems long after they've occured ("downstream")  
- Secondary analyses are inevitably colored by the interests/motivations of others 

### Evidence-based Data Analysis  
- Most data analyses involve stringing together many different tools and methods  
- Some methods may be standard for a given field, but others are often applied ad hoc  
-We should apply thoroughly studied (via statistical research), mutually agreed upon methods to analyze data whenever possible  
- There should be evidence to justify the application of a given method